{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNz3336n1fEedVyLuEifvGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanyun-yang/Neural-Network-1/blob/main/3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2J_uSNROHbF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuba:0' if torch.cuba.is_available else 'cpu')\n",
        "\n",
        "class Net(nn.Moudule):\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,(5,5))\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.fc1 = nn.Linear(16*4*4,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      x = x.view(--1,self.num_flat_features(x))\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.log_softmax(self.fc3(x))\n",
        "\n",
        "      return x\n",
        "      # x --> conv1 -->relu -->pooling -->conv2 --> relu -->pooling --> fully connected\n",
        "    def num_flat_features(self,x):\n",
        "      size = x.size()[1:]\n",
        "      num_features = 1\n",
        "      for s in size:\n",
        "        num_features *=s\n",
        "      return num_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35FKs-m2Svcz"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "\n",
        "  def __init__(self, dir, transform=None):\n",
        "    self.dir = dir\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    files = glob.glob(self.dir+'/*.jpg')[:100]\n",
        "    return len(files)\n",
        "  \n",
        "  def __geitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    all_files = glob.glob(slef.dir+'/*.jpg')[:100]\n",
        "    img_fname = os.path.join(self.dir, all_files[idx])\n",
        "    image = io.imread(img_fname)\n",
        "\n",
        "    digit = int(self.dir.split('/')[-1].strip())\n",
        "    label = np.array(digit)\n",
        "\n",
        "    instance = {'image':image,'label':label}\n",
        "\n",
        "    if self.transform:\n",
        "      instance = self.transform(instance)\n",
        "\n",
        "    return instance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtfFMQ3WU9Hk"
      },
      "source": [
        "class Rescale(object):\n",
        "\n",
        "  def __init__(self, output_size):\n",
        "    assert isinstance(output_size,(int,tuple))\n",
        "    self.output_size = output_size\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    image, label = sample['image'],sample['label']\n",
        "\n",
        "    h,w = image.shape[-2:]\n",
        "    if isinstance(self.output_size, int):\n",
        "      if h > w:\n",
        "        new_h, new_w = self.output_size*h/w, self.output_size\n",
        "      else:\n",
        "        new_h, new_w = self.output_size, self.output_size*w/h\n",
        "    else:\n",
        "      new_h, new_w = self.output_size\n",
        "\n",
        "    new_h, new_w = int(new_h),int(new_w)\n",
        "\n",
        "    new_image = transform.resize(image,(new_h, new_w))\n",
        "\n",
        "    return {'image': new_image, 'label': label}\n",
        "  \n",
        "class ToTensor(object):\n",
        "  def __call__(self, sample):\n",
        "    image, label = sample['image'],sample['label']\n",
        "    image = image.reshape((1, image.shape[0],image.shape[1]))\n",
        "    return ('image':torch.from_numpy(image),'label':torch.from_numpy(label))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwDPnwG3Yq8a"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "from torchvision\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "list_datasets = []\n",
        "for i in range(10):\n",
        "  cur_da = MNISTDataset('')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}