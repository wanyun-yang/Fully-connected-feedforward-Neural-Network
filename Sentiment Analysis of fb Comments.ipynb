{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wanyun_Yang_lab1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMVhBf3fzLnLOQuGChz+FnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanyun-yang/Neural-Network-1/blob/main/Wanyun_Yang_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLCJUkdFuLjp"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5viN9-tkucNG",
        "outputId": "81aa7027-5306-47cc-98ce-62d96063c839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "# import the basic packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# load text data and convert the label/sentiment into corresponding numeric values: \n",
        "fname = 'facebook_comments.csv'\n",
        "df_train = pd.read_csv(fname, header = None, names = ['text', 'sentiment'], encoding = 'iso-8859-1', lineterminator='\\n')\n",
        "sent = {'positive':2, 'neutral':1,'negative':0}\n",
        "df_train['labels'] = df_train['sentiment'].str.strip().map(sent)\n",
        "\n",
        "# get texts and labels\n",
        "training_texts = df_train.text.values\n",
        "labels = df_train.labels.values\n",
        "\n",
        "print(type(training_texts),type(labels))\n",
        "\n",
        "# show the first 5 records\n",
        "df_train.head()"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  labels\n",
              "0  Heres a single  to add  to Kindle. Just read t...    neutral       1\n",
              "1  If you tire of Non-Fiction.. Check out http://...    neutral       1\n",
              "2   Ghost of Round Island is supposedly nonfiction.     neutral       1\n",
              "3  Why is Barnes and Nobles version of the Kindle...   negative       0\n",
              "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSC5sSkUuY7n"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsniyKrFum6P",
        "outputId": "5828c143-42c1-4f32-9590-22879b7871fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# preprocess the loaded textual data, including removing stopwords, stemming, and tokenization\n",
        "# represent each document (i.e., comment) using TF-IDF strategy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# tokenize and create a document-feature matrix X and a label vector Y\n",
        "vectorizer = TfidfVectorizer(stop_words='english',max_features=500,ngram_range=(1,1))\n",
        "instances = vectorizer.fit_transform(training_texts)\n",
        "X = instances.toarray()\n",
        "Y = labels\n",
        "\n",
        "# print out the shape of X and Y\n",
        "print(X.shape,',',Y.shape)\n",
        "\n",
        "# print out part of X and Y\n",
        "print(Y[:10])\n",
        "print(X[0,:50])"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 500) , (1999,)\n",
            "[1 1 1 0 2 2 2 0 2 0]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.28915636 0.         0.         0.\n",
            " 0.         0.         0.2971592  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPu71vgguZYz"
      },
      "source": [
        "# Traditional Machine Learning Models: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAtt2veyuxcO",
        "outputId": "d3475aee-4e61-4261-bece-5b7f42618ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# using 10-fold cross-validation to show the prediction accuracy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "kfold = KFold(n_splits=10,shuffle=True,random_state=2020)\n",
        "rf_model = RandomForestClassifier(criterion='entropy',max_depth=2,random_state=2020)\n",
        "rf_cvscores = []\n",
        "\n",
        "for train_idx,val_idx in kfold.split(X):\n",
        "  rf_model.fit(X[val_idx],Y[val_idx])\n",
        "  acc = rf_model.score(X[val_idx],Y[val_idx])\n",
        "  rf_cvscores.append(acc)\n",
        "\n",
        "print(\"Random Forest - mean: %.4f%% (std: +/- %.4f%%)\" % (np.mean(rf_cvscores)*100, np.std(rf_cvscores)*100))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest - mean: 64.1332% (std: +/- 2.0919%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4asqSiZj1VPn"
      },
      "source": [
        "\n",
        "# Fully connected feedforward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDZRCcjBu_of"
      },
      "source": [
        "# load packages\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WLk065q1nV5"
      },
      "source": [
        "Build the train loader and validation loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtxYz9K-09qm"
      },
      "source": [
        "# Parameters that can make the model better \n",
        "batch_size = 15\n",
        "# when the epochs is 25 or above, the highest valiadation accuracy is around 94-95%, so no need to increase computational waste\n",
        "epochs = 25\n",
        "lr = 0.04\n",
        "indim = X.shape[1]\n",
        "outdim = 3\n",
        "drate = 0.7\n",
        "\n",
        "# Because of the drop out rate, the training data basically cannot be fixed, but I still added the seed to make it relatively more controlable.\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# convert X and Y to matrixs\n",
        "X_tensor = torch.from_numpy(X)\n",
        "Y_tensor = torch.from_numpy(Y)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, Y_tensor)\n",
        "\n",
        "# set 80% data to training set, the rest validation set\n",
        "train_size = int(0.8*len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset,val_dataset = torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True,batch_size = batch_size)\n",
        "val_loader = DataLoader(val_dataset, shuffle=True,batch_size=batch_size)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DVfd5bR1gPG"
      },
      "source": [
        "Build the network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8vMaFfe1eY2",
        "outputId": "4d506260-d17a-4ca6-86bc-e5682d1e2227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# network model itself\n",
        "class SentimentNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, dropout_rate):\n",
        "\n",
        "    super(SentimentNetwork,self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(500,100)\n",
        "    self.fc2 = nn.Linear(100,50)\n",
        "    self.fc3 = nn.Linear(50,3)\n",
        "    self.drop1 = nn.Dropout(drate)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.sigmoid(self.fc1(x))\n",
        "    x = self.drop1(x)\n",
        "    x = F.sigmoid(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return F.log_softmax(x)\n",
        "\n",
        "# Run the model and print the structure \n",
        "model = SentimentNetwork(indim,outdim,drate)\n",
        "print(model)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNetwork(\n",
            "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
            "  (drop1): Dropout(p=0.7, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8nc4jJy1yuH"
      },
      "source": [
        "Create a training function to train the model and an evaluation function to evaluate the\n",
        "performance on the separate validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZUQaZUJ12ba"
      },
      "source": [
        "# define a training process function\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "  epoch_loss,epoch_acc = 0.0,0.0 \n",
        "  model.train()\n",
        "  for batch_x, batch_y in train_loader:\n",
        "    #zero gradient\n",
        "    optimizer.zero_grad()\n",
        "    #prediction\n",
        "    output = model(batch_x.float())\n",
        "    #loss\n",
        "    loss = criterion(output,batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #acc\n",
        "    pred = output.data.max(1)[1]\n",
        "    acc = pred.eq(batch_y.data).sum()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc\n",
        "\n",
        "  #calculate the average epoch_loss and epoch_acc\n",
        "  epoch_loss/=len(train_loader.dataset)\n",
        "  epoch_acc/=len(train_loader.dataset)   \n",
        "  return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "# define a validation/evaluation process function\n",
        "\n",
        "def evaluate(model, val_loader, criterion):\n",
        "   \n",
        "  epoch_loss,correct = 0.0,0.0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_x,batch_y in val_loader:\n",
        "      #prediction\n",
        "      output = model(batch_x.float())\n",
        "      #loss\n",
        "      epoch_loss += criterion(output,batch_y).data\n",
        "      #acc\n",
        "      pred = output.data.max(1)[1]\n",
        "      correct += pred.eq(batch_y.data).sum()\n",
        "\n",
        "  #calculate the average epoch_loss and epoch_acc\n",
        "  epoch_loss/=len(val_loader.dataset)\n",
        "  epoch_acc =correct/len(val_loader.dataset)\n",
        "  return epoch_loss, epoch_acc\n"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0qn2Z8_171_"
      },
      "source": [
        "Main starting point: train the model and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KZ_-iQc2BgC",
        "outputId": "d3696a5f-324b-4b85-891f-31660a7c135e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# define the loss function and optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# real training and evaluation process\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "  print(f'Epoch: {epoch+1:02}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.4f} | Val. Acc: {valid_acc:.4f}')"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.0548 | Train Acc: 0.6423\n",
            "\t Val. Loss: 0.0395 | Val. Acc: 0.7700\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.0381 | Train Acc: 0.7817\n",
            "\t Val. Loss: 0.0336 | Val. Acc: 0.8175\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.0311 | Train Acc: 0.8286\n",
            "\t Val. Loss: 0.0331 | Val. Acc: 0.7925\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.0282 | Train Acc: 0.8424\n",
            "\t Val. Loss: 0.0298 | Val. Acc: 0.8150\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.0255 | Train Acc: 0.8587\n",
            "\t Val. Loss: 0.0300 | Val. Acc: 0.8425\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.0225 | Train Acc: 0.8755\n",
            "\t Val. Loss: 0.0269 | Val. Acc: 0.8700\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.0204 | Train Acc: 0.8862\n",
            "\t Val. Loss: 0.0257 | Val. Acc: 0.8725\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.0189 | Train Acc: 0.8949\n",
            "\t Val. Loss: 0.0258 | Val. Acc: 0.8825\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.0150 | Train Acc: 0.9256\n",
            "\t Val. Loss: 0.0241 | Val. Acc: 0.8850\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.0147 | Train Acc: 0.9287\n",
            "\t Val. Loss: 0.0248 | Val. Acc: 0.9075\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.0147 | Train Acc: 0.9337\n",
            "\t Val. Loss: 0.0241 | Val. Acc: 0.9025\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.0138 | Train Acc: 0.9343\n",
            "\t Val. Loss: 0.0226 | Val. Acc: 0.9175\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.0124 | Train Acc: 0.9375\n",
            "\t Val. Loss: 0.0222 | Val. Acc: 0.9300\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.0117 | Train Acc: 0.9487\n",
            "\t Val. Loss: 0.0211 | Val. Acc: 0.9200\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.0109 | Train Acc: 0.9462\n",
            "\t Val. Loss: 0.0211 | Val. Acc: 0.9275\n",
            "Epoch: 16\n",
            "\tTrain Loss: 0.0109 | Train Acc: 0.9575\n",
            "\t Val. Loss: 0.0212 | Val. Acc: 0.9275\n",
            "Epoch: 17\n",
            "\tTrain Loss: 0.0094 | Train Acc: 0.9543\n",
            "\t Val. Loss: 0.0216 | Val. Acc: 0.9300\n",
            "Epoch: 18\n",
            "\tTrain Loss: 0.0099 | Train Acc: 0.9575\n",
            "\t Val. Loss: 0.0201 | Val. Acc: 0.9350\n",
            "Epoch: 19\n",
            "\tTrain Loss: 0.0098 | Train Acc: 0.9581\n",
            "\t Val. Loss: 0.0197 | Val. Acc: 0.9325\n",
            "Epoch: 20\n",
            "\tTrain Loss: 0.0085 | Train Acc: 0.9619\n",
            "\t Val. Loss: 0.0217 | Val. Acc: 0.9350\n",
            "Epoch: 21\n",
            "\tTrain Loss: 0.0078 | Train Acc: 0.9669\n",
            "\t Val. Loss: 0.0212 | Val. Acc: 0.9400\n",
            "Epoch: 22\n",
            "\tTrain Loss: 0.0083 | Train Acc: 0.9606\n",
            "\t Val. Loss: 0.0203 | Val. Acc: 0.9375\n",
            "Epoch: 23\n",
            "\tTrain Loss: 0.0078 | Train Acc: 0.9662\n",
            "\t Val. Loss: 0.0192 | Val. Acc: 0.9475\n",
            "Epoch: 24\n",
            "\tTrain Loss: 0.0087 | Train Acc: 0.9631\n",
            "\t Val. Loss: 0.0221 | Val. Acc: 0.9425\n",
            "Epoch: 25\n",
            "\tTrain Loss: 0.0086 | Train Acc: 0.9637\n",
            "\t Val. Loss: 0.0207 | Val. Acc: 0.9400\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
